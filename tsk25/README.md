

Підготовка даних
Завантажено 1080 зображень для тренування і 120 — для тестування.

Зображення нормалізовано шляхом ділення пікселів на 255 (перетворення в діапазон [0, 1]).

Мітки перетворено в формат one-hot encoding для багатокласової класифікації.

Проведено візуальну перевірку випадкових зразків даних для впевненості в коректності завантаження.

Архітектура моделі
Використано згорткову нейронну мережу (CNN) з трьома послідовними Conv2D шарами (32, 64, 128 фільтрів).

Кожен згортковий шар супроводжувався MaxPooling для зменшення розмірності.

Після згорткових шарів йшли Flatten, Dense (128 нейронів) з ReLU активацією і Dropout (0.5) для боротьби з перенавчанням.

Вихідний шар із 6 нейронами та активацією softmax для класифікації 6 класів.

Процес навчання
Виконано навчання моделі протягом максимум 30 епох з batch size=32.

Використано EarlyStopping з терпінням 5 епох для зупинки навчання при відсутності покращення.

Застосовано ModelCheckpoint для збереження найкращої моделі за результатами валідації.

Відслідковувалися метрики accuracy та loss на тренувальних і валідаційних даних.

Результати експерименту
Початкова точність навчання близько 17%, що підвищилась до 92.5% за 20 епох.

Валідаційна точність стабілізувалась близько 92-93%.

Втрата (loss) зменшилась з ~1.8 до ~0.18 на кінець навчання.

Classification report показав високі показники precision, recall і F1-score по всіх 6 класах (від 0.84 до 1.00).

Матриця плутанини продемонструвала дуже мало помилок у класифікації.

Модель не перенавчилась завдяки використанню Dropout і EarlyStopping.

Висновки
Використання CNN для задачі класифікації жестів є обґрунтованим і ефективним підходом.

Архітектура з кількома згортковими шарами дозволяє моделі навчатися розпізнавати важливі просторові патерни на зображеннях.

Нормалізація і правильна підготовка даних є критично важливими для успішного навчання.

Використання регуляризації (Dropout) і контролю навчання (EarlyStopping, ModelCheckpoint) запобігло перенавчанню.

Результати тестування підтверджують хорошу узагальнюючу здатність моделі.

Для подальшого покращення можна додати аугментацію даних та/або використати більш складні архітектури або transfer learning.

